{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview for Online Hard Example Mining\n",
    "Yikun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The concept of _\"Online Hard Example Mining\"_ originally comes from a conference paper published in CVPR 2016 named [Training Region-based Object Detectors with Online Hard Example Mining](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Shrivastava_Training_Region-Based_Object_CVPR_2016_paper.html). This algorithms aims at selecting hard examples automatically for training _\"region-based ConvNet detectors\"_ to address the extreme imbalance between hard and easy examples in most datasets . The authors of this paper  claims two major contributions: __1. \"eliminates several heuristics and hyperparameters in common use\"; 2. \"consistent and significant boosts in detection performance\"__ compared to its precursors, including _\"hard negative mining\"_, which is generally the implementation of _boostrapping_ over models like \"SVMs, shallow neural networks and boosted decision trees\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between this algorithm and traditional _hard negative mining_ is that traditional hard negative mining requires iterations between training model and modifying working set (training set), which is harmful to the state-of-the-art model Fast-RCNN at that time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of OHEM\n",
    "\n",
    "The base detector of OHEM in the paper is Fast R-CNN. Based on this paper and the origin paper of Fast R-CNN, the implementation process of Fast R-CNN with OHEM is roughly listed below:  \n",
    "\n",
    "1. Randomly sample __N__ images from dataset as mini-batch;\n",
    "2. For each image, forward it through ConvNet to produce a feature map;\n",
    "3. Combine all input RoIs with current feature map to do forward pass in RoI Net;\n",
    "4. Select __B/N__ worst RoIs for each image by sorting with Loss (__NMS used with 0.7 as threshold__);\n",
    "5. Used selected RoIs to do backward pass, updating model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation Details:\n",
    "1. Intuitive solution:  \n",
    "Keep Network Structure unchanged, sort RoIs based on loss and set the losses of all non-hard RoIs to 0.  \n",
    "Drawbacks: Still allocates memories and performs backward pass for __ALL__ RoIs.  \n",
    "  \n",
    "2. Create _\"Read only\"_ RoI Net:  \n",
    "![img](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As for RoIs:  \n",
    "The __\"RoIs\"__ mentioned in Fast R-CNN are Regions of Interest (boxes) produce by Region Proposal Network (VGG16-conv5 in the case of Fast R-CNN), which plays the same role as the anchor boxes in our case.  \n",
    "(concerns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHEM and similar methods in other articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Class Rectification Loss:\n",
    "The idea is brought up in [this paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Dong_Class_Rectification_Hard_ICCV_2017_paper.pdf), which aims at detect and classify imbalance person attribute data.\n",
    "Adding __\"class rectification loss\"__ to traditional cross-entropy loss to address minority class-level and instance-level hard samples\n",
    "![img1](crl.png)  \n",
    "As for the definition of class-level and instance-level hard examples, only class-level definition is presented here:\n",
    "![img2](class-level.png)  \n",
    "_considering that we don't have the concept of class nor attribute in our case, we might treat it as a binary-classification task in order to implement it._  \n",
    "In order to utilize these minority class-level / instance-level samples. The authors implemented triplet based loss. One of the impelentation is as followed:\n",
    "![img3](triplet.png)\n",
    "where the _mj_ in the formula means the class margin of attribute _j_.\n",
    "#### 2. YOLO v2 with OHEM:\n",
    "An implementation of OHEM with YOLO v2 is presented in [this paper](https://iopscience.iop.org/article/10.1088/1742-6596/1074/1/012085/pdf).  \n",
    "The authors firstly brought up a formula to deal with the imbalance of positive and negative samples in their dataset, which is again related to classification.\n",
    "![img4](loss.png)  \n",
    "After that, the way the really process online hard example mining is similar to what mentioned in the original paper as the _intuitive_ method, which simply:  \n",
    "1. forward pass through the ConvNet, outputs are decided as _positive_ or _negative_ based on IOU;\n",
    "2. Sort negative samples in terms of confidence scores, choose the worst _K_ samples;\n",
    "3. Set the losses of all other negative samples to 0, and do backward pass with all positive samples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "The authors of [this paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w3/Lin_Fast_Vehicle_Detector_ICCV_2017_paper.pdf) utilized a fine-tuned YOLO structure with GoogLeNet as the basenet and the structure of inception_net and OHEM to reach competitive results.\n",
    "The basic strucutre of their model looks like this:\n",
    "![img4](net.png)  \n",
    "They implemented data augmentation to images before feeding them to the model during training phase.  \n",
    "In order to deal with the multi-scale problem better, they utilized an inception_net like structure shown above, together with three prior anchor boxes generated by k-means clustering, like what we did.  \n",
    "As for OHEM implementation, they proposed two ways. First of which is initiated from the original paper, which is selecting certain number of hard examples to do backward pass and set all the others samples to loss 0. However, they claim that this results in trivial improvement in terms of AP, because global hard examples lies in sparse training images instead of __\"real hard examples\"__ with higher loss, in other words, hard examples are chose based on the frequency of appearance. I'm not quite sure if I totally understand this point, if I do, I highly doubt their claim because in the original paper people are dealing with RoIs instead of images.  \n",
    "The way their propsed is called Non-region-based OHEM (NOHEM), which is choosing hard examples based on threshold, cumulate to a certain amount, and do a BP. The figures of both proposal are shown below.\n",
    "![img5](origin.png)\n",
    "![img6](NOHEM.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
